{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "UyseGfrWetBz"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import calendar as cl\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import glob\n",
    "import sqlite3\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "9nJfj-8ks-10"
   },
   "outputs": [],
   "source": [
    "#generamos el rango de fechas para realizar la busqueda\n",
    "\n",
    "Dates = pd.date_range(start='2022-12-01', end='2022-12-31', freq='D', normalize=False)\n",
    "\n",
    "Dates_Series = Dates.to_series().dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scafold project \n",
    "\n",
    "try:\n",
    "  os.makedirs(\"../json/Raw_period_date=2022-12\")\n",
    "except:\n",
    "  pass\n",
    "\n",
    "\n",
    "try:\n",
    "  os.makedirs(\"profiling\")\n",
    "except:\n",
    "  pass\n",
    "\n",
    "\n",
    "try:\n",
    "  os.makedirs(\"../data/Raw_parquet_period=2022-12\")\n",
    "except:\n",
    "  pass\n",
    "\n",
    "try:\n",
    "  os.makedirs(\"../data/master_parquet_period=2022-12\")\n",
    "except:\n",
    "  pass\n",
    "\n",
    "try:\n",
    "  os.makedirs(\"../db/\")\n",
    "except:\n",
    "  pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74lj4p7ut1gA"
   },
   "outputs": [],
   "source": [
    "#@title Data handdler\n",
    "#data handdler\n",
    "\n",
    "\n",
    "# Define the API endpoint\n",
    "index_date = 0\n",
    "\n",
    "for date_find in Dates_Series :\n",
    "  # print(date_find)\n",
    "\n",
    "\n",
    "  response = rq.get(f\"http://api.tvmaze.com/schedule/web?date={date_find}\")\n",
    "\n",
    "  \n",
    "  # valida el status\n",
    "  if response.status_code == 200:\n",
    "      # The request was successful, so parse the response data\n",
    "      data = json.loads(response.content)\n",
    "      # Save the data to a JSON file\n",
    "      with open(f\"../json/Raw_period_date=2022-12/{Dates_Series[date_find]}.json\", \"w\") as f:\n",
    "          json.dump(data, f, indent=4)\n",
    "          f.close()\n",
    "          time.sleep(0.10)\n",
    "  else:\n",
    "      # The request failed, so print the error message\n",
    "      print(response.status_code)\n",
    "      print(response.content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "EFq13hns750u",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "#data profilling\n",
    "\n",
    "def return_profilling_per_date(day):\n",
    "\n",
    "\n",
    "    df = pd.read_json(f\"../json/Raw_period_date=2022-12/{day}.json\")\n",
    "    profiling = df.profile_report(title=f'Profiling {day}')\n",
    "    profiling.to_file(f'../profiling/profiling_{day}.html')\n",
    "\n",
    "    return \"ok\"\n",
    "\n",
    "for date_find in Dates_Series :\n",
    "    return_profilling_per_date(date_find)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#limpieza para columna rating 0 para none \n",
    "\n",
    "def clean_rating(df,column):\n",
    "    \n",
    "   df[column] = df[column].apply(lambda x: x.get(\"average\"))\n",
    "\n",
    "   df[column] = df[column].replace(np.NAN, 0)\n",
    "    \n",
    "   return df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpieza de summary elimanar etiquetas ej: <p>\n",
    "def clean_summary(df, column):\n",
    "\n",
    "    def remove_tags(text):\n",
    "        \"\"\"Removes any type of tag from text.\"\"\"\n",
    "        pattern = re.compile(r\"<[^>]+>\", re.DOTALL)\n",
    "        return pattern.sub(r\"\", text)\n",
    "\n",
    "    df[column] = df[column].apply(lambda x: remove_tags(str(x)))\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## descomponemos la columna _embedded la cual contiene informacion embebida relevante \n",
    "values_id_show = list()\n",
    "def overturn_column_show_embedded_columns(df, key):\n",
    "    values_id_show.clear()\n",
    "    for index_row in range(0,len(df.index)):\n",
    "        values_id_show.append(df[\"_embedded\"][index_row][\"show\"][key])\n",
    "    return values_id_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de cloumnas embebidas \n",
    "list_of_keys = [\n",
    "  \"id\",\n",
    "  \"url\",\n",
    "  \"name\",\n",
    "  \"type\",\n",
    "  \"language\",\n",
    "  \"genres\",\n",
    "  \"status\",\n",
    "  \"runtime\",\n",
    "  \"averageRuntime\",\n",
    "  \"premiered\",\n",
    "  \"ended\",\n",
    "  \"officialSite\",\n",
    "  \"schedule\",\n",
    "  \"rating\",\n",
    "  \"weight\",\n",
    "  \"network\",\n",
    "  \"webChannel\",\n",
    "  \"dvdCountry\",\n",
    "  \"externals\",\n",
    "  \"image\",\n",
    "  \"summary\",\n",
    "  \"updated\",\n",
    "  \"_links\",]\n",
    "\n",
    "def create_columns_ebedded(df):\n",
    "    for key in list_of_keys:\n",
    "        df[f\"show_{key}\"]=overturn_column_show_embedded_columns(df, key)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns_object = [\n",
    "       'url', 'name', 'type','show_url', 'show_type','image','airtime',\n",
    "       'summary', 'show_name','show_language', 'show_genres', \n",
    "       'show_status', 'show_premiered', 'show_ended', 'show_officialSite', \n",
    "       'show_schedule', 'show_network','show_webChannel', 'show_dvdCountry', \n",
    "       'show_externals', 'show_image','show_summary', 'show__links']\n",
    "\n",
    "def cast_object_to_string(df):\n",
    "        for column in list_columns_object:\n",
    "            df[column] = df[column].astype(\"string\")\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_colums_date = [\"airdate\"]\n",
    "\n",
    "def cast_object_to_date(df):\n",
    "    for column in list_of_colums_date:\n",
    "        df[column] = pd.to_datetime(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#captura de data fecha por fecha \n",
    "\n",
    "def wranglind_data(date):\n",
    "\n",
    "    df_day = pd.read_json(f\"../json/Raw_period_date=2022-12/{date}.json\")\n",
    "    create_columns_ebedded(df_day)\n",
    "    clean_summary(df_day,'show_summary')\n",
    "    clean_summary(df_day,'summary')\n",
    "    clean_rating(df_day,\"rating\")\n",
    "    clean_rating(df_day,\"show_rating\")\n",
    "    df_day = df_day.drop(['_embedded'], axis=1)\n",
    "    df_day = df_day.drop(['_links'], axis=1)\n",
    "    cast_object_to_string(df_day)\n",
    "    #cast_object_to_date(df_day)\n",
    "\n",
    "\n",
    "    return df_day\n",
    "\n",
    "\n",
    "    \n",
    "for day_to_wranglind_data in Dates_Series:\n",
    "    data_warngled=wranglind_data(day_to_wranglind_data)\n",
    "    data_warngled.to_parquet(f\"../data/master_parquet_period=2022-12/{day_to_wranglind_data}.snappy.parquet\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lectura de parquets \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## muestra de lectrua de archivo parquet\n",
    "df_parquet = pd.read_parquet(\"../data/master_parquet_period=2022-12/2022-12-31.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## buesqueda recursiva de parquets sobre la carpeta json\n",
    "import pandas as pd\n",
    "\n",
    "file_data_parquet = \"../data/master_parquet_period=2022-12/*.parquet\"\n",
    "files = glob.glob(file_data_parquet, recursive=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenacion de los n parquets en un solo dataframe\n",
    "df = pd.concat([pd.read_parquet(file) for file in files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_type\n",
       "Animation       520\n",
       "Award Show        2\n",
       "Documentary     260\n",
       "Game Show       104\n",
       "News             23\n",
       "Reality         499\n",
       "Scripted       2214\n",
       "Sports           91\n",
       "Talk Show       195\n",
       "Variety          76\n",
       "Name: show_name, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Conteo de shows de tv por género\n",
    "generos_show = df.groupby([df[\"show_type\"]]).count()\n",
    "generos_show[\"show_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_name           show_id\n",
       "#BOOS               40471      25.0\n",
       "1 For All           62858       7.0\n",
       "10 глупых вопросов  40482      23.0\n",
       "110                 62979      40.0\n",
       "13 клиническая      64517      43.0\n",
       "                               ... \n",
       "Я СЕБЯ ЗНАЮ!        47865      67.0\n",
       "Я слежу за тобой    65481       NaN\n",
       "Я тебе не верю      59120      45.0\n",
       "вМесте. Интервью    47027      36.0\n",
       "ебаут               55566      77.2\n",
       "Name: runtime, Length: 747, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## runtime promedio por show\n",
    "df[\"runtime\"].groupby([df[\"show_name\"], df[\"show_id\"]]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_name\n",
       "#BOOS                 [https://www.youtube.com/channel/UCc0kHafEIzm6...\n",
       "1 For All             [https://www.youtube.com/user/deerstalkerpictu...\n",
       "10 глупых вопросов    [https://www.youtube.com/playlist?list=PLLkqhq...\n",
       "110                                       [https://tv.nrk.no/serie/110]\n",
       "13 клиническая           [https://www.ivi.tv/watch/13-ya-klinicheskaya]\n",
       "                                            ...                        \n",
       "Я СЕБЯ ЗНАЮ!          [https://www.youtube.com/playlist?list=PLbwnGd...\n",
       "Я слежу за тобой          [https://premier.one/show/ya-slezhu-za-toboj]\n",
       "Я тебе не верю                [https://ya-tebe-ne-veryu.tnt-online.ru/]\n",
       "вМесте. Интервью                    [http://vmesteproject.ru/intervue/]\n",
       "ебаут                 [https://www.youtube.com/c/%D0%B5%D0%B1%D0%B0%...\n",
       "Name: show_officialSite, Length: 747, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"show_officialSite\"].groupby([df[\"show_name\"]]).unique()\n",
    "# df.show_officialSite.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(f\"../data/master_parquet_period=2022-12/master_data_2022-12.snappy.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crearmos base de datos y tabla  en sqlite\n",
    "\n",
    "# Create a connection to the database\n",
    "conn = sqlite3.connect(\"../db/tv_episodes.db\")\n",
    "\n",
    "# Create a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create the table\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS tv_shows (\n",
    "  id INTEGER PRIMARY KEY NOT NULL,\n",
    "  url TEXT,\n",
    "  name TEXT,\n",
    "  season INTEGER,\n",
    "  number REAL,\n",
    "  type TEXT,\n",
    "  airdate DATETIME,\n",
    "  airtime TEXT,\n",
    "  airstamp OBJECT,\n",
    "  runtime REAL,\n",
    "  rating REAL,\n",
    "  image TEXT,\n",
    "  summary TEXT,\n",
    "  show_id INTEGER NOT NULL,\n",
    "  show_url TEXT,\n",
    "  show_name TEXT,\n",
    "  show_type TEXT,\n",
    "  show_language TEXT,\n",
    "  show_genres TEXT,\n",
    "  show_status TEXT,\n",
    "  show_runtime REAL,\n",
    "  show_averageRuntime REAL,\n",
    "  show_premiered TEXT,\n",
    "  show_ended TEXT,\n",
    "  show_officialSite TEXT,\n",
    "  show_schedule TEXT,\n",
    "  show_rating REAL,\n",
    "  show_weight INTEGER,\n",
    "  show_network TEXT,\n",
    "  show_webChannel TEXT,\n",
    "  show_dvdCountry TEXT,\n",
    "  show_externals TEXT,\n",
    "  show_image TEXT,\n",
    "  show_summary TEXT,\n",
    "  show_updated INTEGER,\n",
    "  show__links TEXT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection to the database\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Importar el archivo Parquet\n",
    "df = pd.read_parquet(\"../data/master_parquet_period=2022-12/master_data_2022-12.snappy.parquet\")\n",
    "\n",
    "# Crear una conexión a la base de datos SQLite\n",
    "conn = sqlite3.connect(\"../db/tv_episodes.db\")\n",
    "\n",
    "\n",
    "# Conexión a la base de datos\n",
    "conn = sqlite3.connect(\"../db/tv_episodes.db\")\n",
    "\n",
    "# Inserta el DataFrame en la tabla\n",
    "df.to_sql(\"tv_shows\", conn, if_exists=\"replace\")\n",
    "\n",
    "# Cierra la conexión\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(id)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(id)\n",
       "0       3984"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Conexión a la base de datos\n",
    "conn = sqlite3.connect(\"../db/tv_episodes.db\")\n",
    "\n",
    "# Obtén la tabla de episodios\n",
    "df = pd.read_sql(\"SELECT COUNT(id) FROM tv_shows\", conn)\n",
    "\n",
    "# Imprime el DataFrame\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
